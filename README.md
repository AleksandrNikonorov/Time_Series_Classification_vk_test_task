# Классификации временных рядов

## Описание проекта
1. **Основная идея** - взять самый большой временной промежуток временных рядов, разбить его на 8 интервалов (по годам) и на этих интервалах посчитать статистики временного ряда, который на нем опредлен. Если для    временного промежутка нет значения ряда - заполняю NaN
   В итоге - получаю датафрейм с 96 признаками (8 интервалов с 12 статистиками на каждом). В гитхаб его выгрузить нельзя, а процесс создания занимает некоторе время, поэтому код и ссылки на загрузку
   предобработанных train.parquet и test.parquet прилагаю в файле  **`load_dataframe.py`**
   
2. В качестве классифицирующей модели лучше всего себя показал CatBoost. В **`my_model_selection.py`** реализован класс для подбора лучших составляющих обученяи (датасета, модели и гиперпараметров)
   Результат сохраняю в таблицу result
   
4. **`MainNavigation`** - основной модуль проекта, объединяющий все возможности.
   - ``create_datasets(train_path, test_path)`` для запуска процесса создания финальных датасетов
   - ``run_model_selection`` запустит перебор по сетке датасетов, моделей и гиперпараметров, обучит лучшую модель на все датасете и сохранит ее
   - ``get_submission`` обученная модель сделает предсказание на тестовых данных и выгрузит их в файл submission.csv
   
### Структура проекта

1. **`load_dataframe`**: 
   - Функция для загрузки предобработанных датасетов с Google Диска
   
2. **`MainNavigation`**: 
   - Основной модуль для запуска работы моделей
   
3. **`create_dataset_functions`**: 
   - Набор функций для создания признаков на основе временных рядов
   
4. **`my_model_selection`**: 
   - Класс для подбора моделей и сравнения результатов между различными датасетами, моделями и их гиперпараметрами
   
5. **`EDA`**: 
   - Модуль для предварительного анализа временных рядов. Он позволяет исследовать структуру данных перед их использованием в модели. (Эта часть работы была начата, но еще не завершена).
6. **`trained_BestModel_catboost_on_rolling_Intervals_12Stats_0.pkl`**
   - Предобученная модель

### Подготовка данных:

1. **Download data**:
   Датасеты предобрабатываются и хранятся на Google Диске. Чтобы загрузить их, используйте функцию `load_dataframe`, которая позволяет получить доступ к нужным данным.

2. **Predictions**
   Запустите скрипт из MainNavigation для создания submission.csv


